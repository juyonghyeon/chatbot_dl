{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da9dc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import TFGPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5153ee8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFGPT2LMHeadModel: ['transformer.h.7.attn.masked_bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.4.attn.masked_bias', 'lm_head.weight', 'transformer.h.11.attn.masked_bias', 'transformer.h.2.attn.masked_bias']\n",
      "- This IS expected if you are initializing TFGPT2LMHeadModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFGPT2LMHeadModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFGPT2LMHeadModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('skt/kogpt2-base-v2', bos_token='<s>', eos_token='</s>', pad_token='<pad>')\n",
    "model = TFGPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2', from_pt=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92bea52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tfgpt2lm_head_model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " transformer (TFGPT2MainLay  multiple                  125164032 \n",
      " er)                                                             \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 125164032 (477.46 MB)\n",
      "Trainable params: 125164032 (477.46 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c64c5d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='skt/kogpt2-base-v2', vocab_size=51200, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<|endoftext|>', 'pad_token': '<pad>'}, clean_up_tokenization_spaces=False, added_tokens_decoder={\n",
       "\t0: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"<usr>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"<sys>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t5: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t6: AddedToken(\"<mask>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t7: AddedToken(\"<d>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t8: AddedToken(\"</d>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t9: AddedToken(\"<unused0>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t10: AddedToken(\"<unused1>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t11: AddedToken(\"<unused2>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t12: AddedToken(\"<unused3>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t13: AddedToken(\"<unused4>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t14: AddedToken(\"<unused5>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t15: AddedToken(\"<unused6>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t16: AddedToken(\"<unused7>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t17: AddedToken(\"<unused8>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t18: AddedToken(\"<unused9>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t19: AddedToken(\"<unused10>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t20: AddedToken(\"<unused11>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t21: AddedToken(\"<unused12>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t22: AddedToken(\"<unused13>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t23: AddedToken(\"<unused14>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t24: AddedToken(\"<unused15>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t25: AddedToken(\"<unused16>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t26: AddedToken(\"<unused17>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t27: AddedToken(\"<unused18>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t28: AddedToken(\"<unused19>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t29: AddedToken(\"<unused20>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t30: AddedToken(\"<unused21>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t31: AddedToken(\"<unused22>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t32: AddedToken(\"<unused23>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t33: AddedToken(\"<unused24>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t34: AddedToken(\"<unused25>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t35: AddedToken(\"<unused26>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t36: AddedToken(\"<unused27>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t37: AddedToken(\"<unused28>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t38: AddedToken(\"<unused29>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t39: AddedToken(\"<unused30>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t40: AddedToken(\"<unused31>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t41: AddedToken(\"<unused32>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t42: AddedToken(\"<unused33>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t43: AddedToken(\"<unused34>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t44: AddedToken(\"<unused35>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t45: AddedToken(\"<unused36>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t46: AddedToken(\"<unused37>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t47: AddedToken(\"<unused38>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t48: AddedToken(\"<unused39>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t49: AddedToken(\"<unused40>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50: AddedToken(\"<unused41>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t51: AddedToken(\"<unused42>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t52: AddedToken(\"<unused43>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t53: AddedToken(\"<unused44>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t54: AddedToken(\"<unused45>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t55: AddedToken(\"<unused46>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t56: AddedToken(\"<unused47>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t57: AddedToken(\"<unused48>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t58: AddedToken(\"<unused49>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t59: AddedToken(\"<unused50>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t60: AddedToken(\"<unused51>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t61: AddedToken(\"<unused52>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t62: AddedToken(\"<unused53>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t63: AddedToken(\"<unused54>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t64: AddedToken(\"<unused55>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t65: AddedToken(\"<unused56>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t66: AddedToken(\"<unused57>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t67: AddedToken(\"<unused58>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t68: AddedToken(\"<unused59>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t69: AddedToken(\"<unused60>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t70: AddedToken(\"<unused61>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t71: AddedToken(\"<unused62>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t72: AddedToken(\"<unused63>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t73: AddedToken(\"<unused64>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t74: AddedToken(\"<unused65>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t75: AddedToken(\"<unused66>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t76: AddedToken(\"<unused67>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t77: AddedToken(\"<unused68>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t78: AddedToken(\"<unused69>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t79: AddedToken(\"<unused70>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t80: AddedToken(\"<unused71>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t81: AddedToken(\"<unused72>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t82: AddedToken(\"<unused73>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t83: AddedToken(\"<unused74>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t84: AddedToken(\"<unused75>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t85: AddedToken(\"<unused76>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t86: AddedToken(\"<unused77>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t87: AddedToken(\"<unused78>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t88: AddedToken(\"<unused79>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t89: AddedToken(\"<unused80>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t90: AddedToken(\"<unused81>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t91: AddedToken(\"<unused82>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t92: AddedToken(\"<unused83>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t93: AddedToken(\"<unused84>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t94: AddedToken(\"<unused85>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t95: AddedToken(\"<unused86>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t96: AddedToken(\"<unused87>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t97: AddedToken(\"<unused88>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t98: AddedToken(\"<unused89>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t99: AddedToken(\"<unused90>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t100: AddedToken(\"<unused91>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t101: AddedToken(\"<unused92>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t102: AddedToken(\"<unused93>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t103: AddedToken(\"<unused94>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t104: AddedToken(\"<unused95>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t105: AddedToken(\"<unused96>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t106: AddedToken(\"<unused97>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t107: AddedToken(\"<unused98>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t108: AddedToken(\"<unused99>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t109: AddedToken(\":-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t110: AddedToken(\":)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t111: AddedToken(\"-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t112: AddedToken(\"(-:\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t113: AddedToken(\"(:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t114: AddedToken(\"(:-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t115: AddedToken(\"-}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t116: AddedToken(\"8-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t117: AddedToken(\"'-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t118: AddedToken(\":-#\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t119: AddedToken(\":-*\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t120: AddedToken(\":-/\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t121: AddedToken(\":->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t122: AddedToken(\":-@\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t123: AddedToken(\":-d\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t124: AddedToken(\":-V\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t125: AddedToken(\":-X\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t126: AddedToken(\":-\\\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t127: AddedToken(\":-]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t128: AddedToken(\";-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t129: AddedToken(\">;->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t130: AddedToken(\";^)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t131: AddedToken(\"%-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t132: AddedToken(\"):-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t133: AddedToken(\"3:]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t134: AddedToken(\":-&\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t135: AddedToken(\"8:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t136: AddedToken(\":-)8<\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t137: AddedToken(\":-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t138: AddedToken(\":-6\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t139: AddedToken(\"+:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t140: AddedToken(\"O:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t141: AddedToken(\":-<\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t142: AddedToken(\":-?\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t143: AddedToken(\":-E\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t144: AddedToken(\":-Q\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t145: AddedToken(\":-}X\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t146: AddedToken(\":-[\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t147: AddedToken(\":-a\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t148: AddedToken(\":-{\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t149: AddedToken(\":-{}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t150: AddedToken(\":^)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t151: AddedToken(\"<:-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t152: AddedToken(\":=)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t153: AddedToken(\">:->\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t154: AddedToken(\">:-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t155: AddedToken(\"@:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t156: AddedToken(\"@:-}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t157: AddedToken(\"C=:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t158: AddedToken(\"X:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t159: AddedToken(\"[:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t160: AddedToken(\"[:]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t161: AddedToken(\"{:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t162: AddedToken(\"l^o\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t163: AddedToken(\"}:^#)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t164: AddedToken(\":-(=)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t165: AddedToken(\"O-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t166: AddedToken(\":-3\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t167: AddedToken(\":=\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t168: AddedToken(\":-\"\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t169: AddedToken(\"P-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t170: AddedToken(\"?-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t171: AddedToken(\"d:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t172: AddedToken(\":8)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t173: AddedToken(\":-7\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t174: AddedToken(\"):-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t175: AddedToken(\":/\\)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t176: AddedToken(\"8(:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t177: AddedToken(\"([(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t178: AddedToken(\":-(*)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t179: AddedToken(\"&-l\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t180: AddedToken(\":-e\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t181: AddedToken(\":(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t182: AddedToken(\":,(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t183: AddedToken(\":-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t184: AddedToken(\":-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t185: AddedToken(\":-S\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t186: AddedToken(\":-C\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t187: AddedToken(\":-r\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t188: AddedToken(\":-t\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t189: AddedToken(\":-W\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t190: AddedToken(\"X-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t191: AddedToken(\"l-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t192: AddedToken(\"l:-O\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t193: AddedToken(\"$-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t194: AddedToken(\":-!\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t195: AddedToken(\":----}\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t196: AddedToken(\"=:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t197: AddedToken(\"=:-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t198: AddedToken(\"3:[\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t199: AddedToken(\"8<:-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t200: AddedToken(\":#)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t201: AddedToken(\"8-#\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t202: AddedToken(\"B-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t203: AddedToken(\"8-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t204: AddedToken(\"|-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t205: AddedToken(\"H-)\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t206: AddedToken(\"]-I\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t207: AddedToken(\"V^J\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t208: AddedToken(\"+-(\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t209: AddedToken(\"~:-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t210: AddedToken(\"`'\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t211: AddedToken(\"L-P\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t212: AddedToken(\"BI\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t213: AddedToken(\"O|\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t214: AddedToken(\"^^\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t215: AddedToken(\"ã…œã…œ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t216: AddedToken(\"ã… ã… \", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t217: AddedToken(\"ã…¡ã…¡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t218: AddedToken(\"ðŸ˜ \", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t219: AddedToken(\"ðŸ‘¿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t220: AddedToken(\"ðŸ˜§\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t221: AddedToken(\"ðŸ˜°\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t222: AddedToken(\"ðŸ˜²\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t223: AddedToken(\"ðŸ˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t224: AddedToken(\"ðŸ»\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t225: AddedToken(\"ðŸ±\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t226: AddedToken(\"ðŸ˜¹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t227: AddedToken(\"ðŸ˜¼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t228: AddedToken(\"ðŸ¤¡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t229: AddedToken(\"ðŸ¥¶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t230: AddedToken(\"ðŸ˜–\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t231: AddedToken(\"ðŸ˜•\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t232: AddedToken(\"ðŸ®\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t233: AddedToken(\"ðŸ¤ \", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t234: AddedToken(\"ðŸ˜¿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t235: AddedToken(\"ðŸ˜¢\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t236: AddedToken(\"ðŸ˜ž\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t237: AddedToken(\"ðŸ˜µ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t238: AddedToken(\"ðŸ¶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t239: AddedToken(\"ðŸ˜“\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t240: AddedToken(\"ðŸ²\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t241: AddedToken(\"ðŸ¤¤\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t242: AddedToken(\"ðŸ˜‘\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t243: AddedToken(\"ðŸ˜˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t244: AddedToken(\"ðŸ˜‹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t245: AddedToken(\"ðŸ˜±\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t246: AddedToken(\"ðŸ¤®\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t247: AddedToken(\"ðŸ¤­\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t248: AddedToken(\"ðŸ¤•\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t249: AddedToken(\"ðŸ˜·\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t250: AddedToken(\"ðŸ§\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t251: AddedToken(\"ðŸ˜®\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t252: AddedToken(\"ðŸ¤¨\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t253: AddedToken(\"ðŸ™„\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t254: AddedToken(\"ðŸ˜¤\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t255: AddedToken(\"ðŸ¤¬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t256: AddedToken(\"ðŸ˜‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t257: AddedToken(\"ðŸ¤’\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t258: AddedToken(\"ðŸ˜›\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t259: AddedToken(\"ðŸ˜¶\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t260: AddedToken(\"ðŸ˜¨\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t261: AddedToken(\"ðŸŒ›\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t262: AddedToken(\"ðŸ˜³\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t263: AddedToken(\"ðŸ¦Š\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t264: AddedToken(\"ðŸ¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t265: AddedToken(\"â˜¹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t266: AddedToken(\"â˜¹ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t267: AddedToken(\"ðŸ˜¦\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t268: AddedToken(\"ðŸŒ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t269: AddedToken(\"ðŸ˜¬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t270: AddedToken(\"ðŸ˜º\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t271: AddedToken(\"ðŸ˜¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t272: AddedToken(\"ðŸ˜€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t273: AddedToken(\"ðŸ˜ƒ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t274: AddedToken(\"ðŸ˜„\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t275: AddedToken(\"ðŸ˜…\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t276: AddedToken(\"ðŸ˜†\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t277: AddedToken(\"ðŸ¹\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t278: AddedToken(\"ðŸ´\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t279: AddedToken(\"ðŸ¥µ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t280: AddedToken(\"ðŸ¤—\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t281: AddedToken(\"ðŸ˜¯\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t282: AddedToken(\"ðŸ˜½\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t283: AddedToken(\"ðŸ˜—\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t284: AddedToken(\"ðŸ˜š\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t285: AddedToken(\"ðŸ˜™\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t286: AddedToken(\"ðŸŒœ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t287: AddedToken(\"ðŸ¦\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t288: AddedToken(\"ðŸ˜­\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t289: AddedToken(\"ðŸ¤¥\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t290: AddedToken(\"ðŸ¤¦ðŸ¿â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t291: AddedToken(\"ðŸ¤¦ðŸ»â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t292: AddedToken(\"ðŸ¤¦ðŸ¾â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t293: AddedToken(\"ðŸ¤¦ðŸ¼â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t294: AddedToken(\"ðŸ¤¦ðŸ½â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t295: AddedToken(\"ðŸ¤¦â€â™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t296: AddedToken(\"ðŸ¤¦ðŸ¿â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t297: AddedToken(\"ðŸ¤¦ðŸ»â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t298: AddedToken(\"ðŸ¤¦ðŸ¾â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t299: AddedToken(\"ðŸ¤¦ðŸ¼â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t300: AddedToken(\"ðŸ¤¦ðŸ½â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t301: AddedToken(\"ðŸ¤¦â€â™‚ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t302: AddedToken(\"ðŸ¤‘\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t303: AddedToken(\"ðŸµ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t304: AddedToken(\"ðŸ­\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t305: AddedToken(\"ðŸ¤¢\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t306: AddedToken(\"ðŸ¤“\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t307: AddedToken(\"ðŸ˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t308: AddedToken(\"ðŸŒš\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t309: AddedToken(\"ðŸ¼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t310: AddedToken(\"ðŸ¥³\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t311: AddedToken(\"ðŸ˜”\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t312: AddedToken(\"ðŸ˜£\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t313: AddedToken(\"ðŸ¤¦\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t314: AddedToken(\"ðŸ¤¦ðŸ¿\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t315: AddedToken(\"ðŸ¤¦ðŸ»\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t316: AddedToken(\"ðŸ¤¦ðŸ¾\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t317: AddedToken(\"ðŸ¤¦ðŸ¼\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t318: AddedToken(\"ðŸ¤¦ðŸ½\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t319: AddedToken(\"ðŸ·\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t320: AddedToken(\"ðŸ¥º\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t321: AddedToken(\"ðŸ˜¾\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t322: AddedToken(\"ðŸ˜¡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t323: AddedToken(\"ðŸ°\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t324: AddedToken(\"ðŸ˜Œ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t325: AddedToken(\"ðŸ¤–\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t326: AddedToken(\"ðŸ˜¥\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t327: AddedToken(\"ðŸ¤«\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t328: AddedToken(\"ðŸ˜´\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t329: AddedToken(\"ðŸ˜ª\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t330: AddedToken(\"ðŸ™\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t331: AddedToken(\"ðŸ™‚\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t332: AddedToken(\"ðŸ˜»\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t333: AddedToken(\"â˜º\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t334: AddedToken(\"â˜ºï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t335: AddedToken(\"ðŸ¥°\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t336: AddedToken(\"ðŸ˜‡\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t337: AddedToken(\"ðŸ˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t338: AddedToken(\"ðŸ˜ˆ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t339: AddedToken(\"ðŸ˜Š\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t340: AddedToken(\"ðŸ˜Ž\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t341: AddedToken(\"ðŸ˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t342: AddedToken(\"ðŸ¤§\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t343: AddedToken(\"ðŸ˜\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t344: AddedToken(\"ðŸŒž\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t345: AddedToken(\"ðŸ¤”\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t346: AddedToken(\"ðŸ¯\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t347: AddedToken(\"ðŸ˜«\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t348: AddedToken(\"ðŸ˜’\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t349: AddedToken(\"ðŸ¦„\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t350: AddedToken(\"ðŸ™ƒ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t351: AddedToken(\"ðŸ™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t352: AddedToken(\"ðŸ˜©\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t353: AddedToken(\"ðŸŒ¬\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t354: AddedToken(\"ðŸŒ¬ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t355: AddedToken(\"ðŸ˜‰\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t356: AddedToken(\"ðŸ˜œ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t357: AddedToken(\"ðŸº\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t358: AddedToken(\"ðŸ¤¦ðŸ¿â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t359: AddedToken(\"ðŸ¤¦ðŸ»â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t360: AddedToken(\"ðŸ¤¦ðŸ¾â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t361: AddedToken(\"ðŸ¤¦ðŸ¼â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t362: AddedToken(\"ðŸ¤¦ðŸ½â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t363: AddedToken(\"ðŸ¤¦â€â™€\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t364: AddedToken(\"ðŸ¤¦ðŸ¿â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t365: AddedToken(\"ðŸ¤¦ðŸ»â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t366: AddedToken(\"ðŸ¤¦ðŸ¾â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t367: AddedToken(\"ðŸ¤¦ðŸ¼â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t368: AddedToken(\"ðŸ¤¦ðŸ½â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t369: AddedToken(\"ðŸ¤¦â€â™€ï¸\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t370: AddedToken(\"ðŸ¥´\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t371: AddedToken(\"ðŸ˜Ÿ\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t372: AddedToken(\"ðŸ¥±\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t373: AddedToken(\"ðŸ¤ª\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t374: AddedToken(\"ðŸ¤\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t51200: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5e3272b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51200"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8080f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12ì‹œ ë•¡!</td>\n",
       "      <td>í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´</td>\n",
       "      <td>ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤</td>\n",
       "      <td>ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PPL ì‹¬í•˜ë„¤</td>\n",
       "      <td>ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Q            A  label\n",
       "0           12ì‹œ ë•¡!   í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.      0\n",
       "1      1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´    ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.      0\n",
       "2     3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "3  3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤  ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .      0\n",
       "4          PPL ì‹¬í•˜ë„¤   ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .      0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data1 = pd.read_csv(\"data/data1.csv\")\n",
    "data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2cbd63e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>req</th>\n",
       "      <th>res</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ë„ˆ ì¢‹ì•„í•˜ëŠ” ì°¨ ì¢…ë¥˜ ìžˆì–´?</td>\n",
       "      <td>ë¬´ìŠ¨ ì°¨? ìžë™ì°¨? ë§ˆì‹œëŠ” ì°¨?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ã…‹ã…‹ ë§ˆì‹œëŠ” ì°¨ ë§í•œ ê±°ì•¼!</td>\n",
       "      <td>ì•„í•˜ ë‚˜ ë‘¥ê¸€ë ˆ, ì˜¥ìˆ˜ìˆ˜, ë³´ë¦¬ì°¨ ì¢‹ì•„í•´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ì™„ì „ ê³¡ë¬¼ë¥˜ ì¢‹ì•„í•˜ë„¤ ã…‹ã…‹</td>\n",
       "      <td>ì•¼ì“° ë“ì´ê¸° ê·€ì°®ì•„ì„œ ëƒ‰ì¹¨í•´ ë¨¹ì–´</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ê·¸ëŸ¼ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ì•Šì•„?</td>\n",
       "      <td>ë“ì´ëŠ” ê²ƒë³´ë‹¤ëŠ” í›¨ì”¬ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ã… </td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ê·¼ë° ëƒ‰ì¹¨ í•˜ëŠ” ê²ƒë„ ê·€ì°®ê² ë‹¤ ã…œã… </td>\n",
       "      <td>ì‘! ê·¸ëž˜ì„œ ë§¤ì¼ì€ ì•ˆ ë¨¹ê³  ê°€ë” ë§ˆì…”</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   req                     res\n",
       "0      ë„ˆ ì¢‹ì•„í•˜ëŠ” ì°¨ ì¢…ë¥˜ ìžˆì–´?       ë¬´ìŠ¨ ì°¨? ìžë™ì°¨? ë§ˆì‹œëŠ” ì°¨?\n",
       "1      ã…‹ã…‹ ë§ˆì‹œëŠ” ì°¨ ë§í•œ ê±°ì•¼!  ì•„í•˜ ë‚˜ ë‘¥ê¸€ë ˆ, ì˜¥ìˆ˜ìˆ˜, ë³´ë¦¬ì°¨ ì¢‹ì•„í•´\n",
       "2       ì™„ì „ ê³¡ë¬¼ë¥˜ ì¢‹ì•„í•˜ë„¤ ã…‹ã…‹      ì•¼ì“° ë“ì´ê¸° ê·€ì°®ì•„ì„œ ëƒ‰ì¹¨í•´ ë¨¹ì–´\n",
       "3        ê·¸ëŸ¼ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ì•Šì•„?    ë“ì´ëŠ” ê²ƒë³´ë‹¤ëŠ” í›¨ì”¬ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ã… \n",
       "4  ê·¼ë° ëƒ‰ì¹¨ í•˜ëŠ” ê²ƒë„ ê·€ì°®ê² ë‹¤ ã…œã…    ì‘! ê·¸ëž˜ì„œ ë§¤ì¼ì€ ì•ˆ ë¨¹ê³  ê°€ë” ë§ˆì…”"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_csv(\"data/data2.csv\")\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fe91eaf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('12ì‹œ ë•¡!', 'í•˜ë£¨ê°€ ë˜ ê°€ë„¤ìš”.'),\n",
       " ('1ì§€ë§ í•™êµ ë–¨ì–´ì¡Œì–´', 'ìœ„ë¡œí•´ ë“œë¦½ë‹ˆë‹¤.'),\n",
       " ('3ë°•4ì¼ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .'),\n",
       " ('3ë°•4ì¼ ì •ë„ ë†€ëŸ¬ê°€ê³  ì‹¶ë‹¤', 'ì—¬í–‰ì€ ì–¸ì œë‚˜ ì¢‹ì£ .'),\n",
       " ('PPL ì‹¬í•˜ë„¤', 'ëˆˆì‚´ì´ ì°Œí‘¸ë ¤ì§€ì£ .'),\n",
       " ('SDì¹´ë“œ ë§ê°€ì¡Œì–´', 'ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ íŽ¸í•´ìš”.'),\n",
       " ('SDì¹´ë“œ ì•ˆë¼', 'ë‹¤ì‹œ ìƒˆë¡œ ì‚¬ëŠ” ê²Œ ë§ˆìŒ íŽ¸í•´ìš”.'),\n",
       " ('SNS ë§žíŒ” ì™œ ì•ˆí•˜ì§€ã… ã… ', 'ìž˜ ëª¨ë¥´ê³  ìžˆì„ ìˆ˜ë„ ìžˆì–´ìš”.'),\n",
       " ('SNS ì‹œê°„ë‚­ë¹„ì¸ ê±° ì•„ëŠ”ë° ë§¤ì¼ í•˜ëŠ” ì¤‘', 'ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.'),\n",
       " ('SNS ì‹œê°„ë‚­ë¹„ì¸ë° ìžê¾¸ ë³´ê²Œë¨', 'ì‹œê°„ì„ ì •í•˜ê³  í•´ë³´ì„¸ìš”.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data = list(zip(data1['Q'].to_list(), data1['A'].to_list()))\n",
    "chat_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b13a9c99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ë„ˆ ì¢‹ì•„í•˜ëŠ” ì°¨ ì¢…ë¥˜ ìžˆì–´?', 'ë¬´ìŠ¨ ì°¨? ìžë™ì°¨? ë§ˆì‹œëŠ” ì°¨?'),\n",
       " ('ã…‹ã…‹ ë§ˆì‹œëŠ” ì°¨ ë§í•œ ê±°ì•¼!', 'ì•„í•˜ ë‚˜ ë‘¥ê¸€ë ˆ, ì˜¥ìˆ˜ìˆ˜, ë³´ë¦¬ì°¨ ì¢‹ì•„í•´'),\n",
       " ('ì™„ì „ ê³¡ë¬¼ë¥˜ ì¢‹ì•„í•˜ë„¤ ã…‹ã…‹', 'ì•¼ì“° ë“ì´ê¸° ê·€ì°®ì•„ì„œ ëƒ‰ì¹¨í•´ ë¨¹ì–´'),\n",
       " ('ê·¸ëŸ¼ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ì•Šì•„?', 'ë“ì´ëŠ” ê²ƒë³´ë‹¤ëŠ” í›¨ì”¬ ì˜¤ëž˜ ê±¸ë¦¬ì§€ ã… '),\n",
       " ('ê·¼ë° ëƒ‰ì¹¨ í•˜ëŠ” ê²ƒë„ ê·€ì°®ê² ë‹¤ ã…œã… ', 'ì‘! ê·¸ëž˜ì„œ ë§¤ì¼ì€ ì•ˆ ë¨¹ê³  ê°€ë” ë§ˆì…”'),\n",
       " ('ê·¸ëŸ¼ ì—„ì²­ ê·€ì°®ì§€ëŠ” ì•Šê² ë„¤?', 'ê·¸ì¹˜ ë§¤ì¼ ë§ˆì‹œë©´ ë§¤ì¼ í•´ì•¼ ë˜ìž–ì•„'),\n",
       " ('ìŒ ìƒê°í•´ ë³´ë‹ˆê¹ ê·¸ë ‡ê¸´ í•˜ë„¤', 'ì–¸ë‹ˆëŠ” ë¬´ìŠ¨ ì°¨ ì¢‹ì•„í•˜ëŠ”ë°?'),\n",
       " ('ë‚˜ëŠ” ë°€í¬í‹°ë„ ì¢‹ì•„í•˜ê³  ë£¨ì´ë³´ìŠ¤ë„ ì¢‹ì•„í•´', 'ì˜¤ ê³ ê¸‰ì ¸ ë‚˜ íŽ˜í¼ë¯¼íŠ¸ë„ ì¢‹ì•„í•œë‹¤!'),\n",
       " ('ë„ˆ êµ¬í•´ì¤˜ í™ˆì¦ˆ ë´?', 'ë§¤ë²ˆ ë³´ëŠ” ê±´ ì•„ë‹ˆê³  ê°€ë”! ì™€ì´?'),\n",
       " ('ë‚˜ ì§€ê¸ˆ ë³´ëŠ” ì¤‘ì¸ë° ì„œìš¸ì€ ì§„ì§œ ë¹„ì‹¸ë‹¤ ì‹¶ì–´ì„œ ã…‹ã…‹', 'ê·¸ì¹˜ ã…  ê·¼ë° ë‚˜ì˜¤ëŠ” ì‚¬ëžŒë“¤ ë‹¤ ë¶€ìžì¸ê°€ ë´')]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data2 = list(zip(data2['req'].to_list(), data2['res'].to_list()))\n",
    "chat_data2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73a3083e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100797"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_data.extend(chat_data2)\n",
    "len(chat_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4135707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chat_data():\n",
    "    # global chat_data ì•ˆì¨ë„ë¨\n",
    "    bos_token = tokenizer.bos_token\n",
    "    eos_token = tokenizer.eos_token\n",
    "    for question, answer in chat_data:\n",
    "        sent = f\"{bos_token}<usr>{question}<sys>{answer}{eos_token}\"\n",
    "        yield tokenizer.encode(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9ada147d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 9349, 7888, 739, 7318, 376, 4, 12557, 6824, 9108, 9028, 7098, 25856, 1]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen = get_chat_data()\n",
    "next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "348e08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataset = tf.data.Dataset.from_generator(get_chat_data, output_types=tf.int32)\n",
    "\n",
    "dataset = dataset.padded_batch(batch_size=batch_size, padded_shapes=(None,), padding_values=tokenizer.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7700c672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[    0     2  9349  7888   739  7318   376     4 12557  6824  9108  9028\n",
      "   7098 25856     1     3     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9020  8263  7497 10192 11615  8210  8006     4 12422  8711\n",
      "   9535  7483 12521     1     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9085  7597   395  8149 10624  7397 24224 13358  7182     4\n",
      "  12079  8135 16899  9677  8234   389     1     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9085  7597   395  8149  9465 10624  7397 24224 13358  7182\n",
      "      4 12079  8135 16899  9677  8234   389     1     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9943   422   418  9327  8702  7098     4  9847 16912 18328\n",
      "   8671  7415  8263  8234   389     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815   410 21249 10174  6824  8210  8006     4  9427 11056\n",
      "  11594 10137 10556  9266  8711 25856     1     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815   410 21249  9183  7249     4  9427 11056 11594 10137\n",
      "  10556  9266  8711 25856     1     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815 37655  9622  8619 10401  9183  9328   216     4  9443\n",
      "  29490  9846  9788  9341 25856     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815 37655 10135  7066 39488  9122  9050  9668 16576  9277\n",
      "   9044     4 15148 19658  9098  7652  7801 25856     1     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815 37655 10135  7066  7692 11848  9042  7019 20284  7254\n",
      "      4 15148 19658  9098  7652  7801 25856     1     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9815 37655 18381  9063  7489 29615  9054 15730 29452  8030\n",
      "      4 33254 10300 23775 25856     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 19319 48397  8711     4  9022 19858 27031  9122  8046 25856\n",
      "      1     3     3     3     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 19319 46651 27481 48397  8711     4  9022 19858 27031  9122\n",
      "   8046 25856     1     3     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 19319  8135  9749 10225  6866  9677  7182     4  9749  9589\n",
      "  20540  7801 25856     1     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 17230 17429  9160  8098     4 10855  8135  9427 35813  9122\n",
      "   8046 25856     1     3     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 47980 22227 26992  7058  7182     4 26992  8137  9376  8737\n",
      "   8236  7801 25856     1     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 26629 23799   739  8308  7304 10174  8707     4  9105  7788\n",
      "  16346  6889  9282  8400  7601  9078  7801 25856     1     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 15983  7673 24648  6889 25880  8006     4 16173 15582 46439\n",
      "  35557  6889 12252  7801 25856     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 15983  7673 24648 15010 10926  6853 27511     4 16173 15582\n",
      "  46439 35557  6889 12252  7801 25856     1     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 15983  7692 12371  9564 16409  9016     4  9536  9271  9052\n",
      "   9267 27545  8711  7661 25856     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 15983  7692 36684  7220  9244  6958  9539  7478  6872  8006\n",
      "      4 46503  9024  7801  8084   376     1     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 15983  7692 26873  9050  7177     4  9536  9271  9052  9267\n",
      "  27545  8711  7661 25856     1     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2  9278 20861  9193   739  7570 47804     4  9278 20861 32392\n",
      "  10070 10828 25856  9105 12114  9094 12191 12700 31279  8702 38887 15148\n",
      "  35441  9328  9109  7801 25856     1]\n",
      " [    0     2 10464 12079  9028  9926  9651  8006     4  9586 27820  9432\n",
      "  23100 21833 14247 29462  7801 25856     1     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464 12079 17577     4  9586 27820  9432 23100 21833 14247\n",
      "  29462  7801 25856     1     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464 12079 42076  9340   406     4  9586 27820  9432 23100\n",
      "  21833 14247 29462  7801 25856     1     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464  9341   406     4  9265  7470  9659  9701 11389 11676\n",
      "   7177   387  9265  7380 11120  8711 10764 11389  9728 12245 22238  9341\n",
      "   8084     1     3     3     3     3]\n",
      " [    0     2 10464 10143  9666   739  8244     4  9265  7470  9659  9701\n",
      "  11389 11676  7177   387  9265  7380 11120  8711 10764 11389  9728 12245\n",
      "  22238  9341  8084     1     3     3]\n",
      " [    0     2 10464 18264 12079  6826  9016     4  9267 25772  8267 25012\n",
      "   9069  6872  7098 25856     1     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464  7285 10056 25799     4  9265  7235 25856     1     3\n",
      "      3     3     3     3     3     3     3     3     3     3     3     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464  9136  7380  9071  7513  8711     4  9054  7285  9117\n",
      "   7703  7788 11120  8705 14553 10667  8718  7055  7661 25856     1     3\n",
      "      3     3     3     3     3     3]\n",
      " [    0     2 10464  9136  7380  9071  7513  8711  8210  8006     4  9054\n",
      "   7285  9117  7703  7788 11120  8705 14553 10667  8718  7055  7661 25856\n",
      "      1     3     3     3     3     3]], shape=(32, 30), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataset):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a367ce8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m     result = model(batch, labels=batch)\n\u001b[32m     15\u001b[39m     batch_loss = tf.reduce_mean(result[\u001b[32m0\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     grads = \u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m     adam.apply_gradients(\u001b[38;5;28mzip\u001b[39m(grads, model.trainable_variables))\n\u001b[32m     19\u001b[39m train_loss += batch_loss\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:1066\u001b[39m, in \u001b[36mGradientTape.gradient\u001b[39m\u001b[34m(self, target, sources, output_gradients, unconnected_gradients)\u001b[39m\n\u001b[32m   1060\u001b[39m   output_gradients = (\n\u001b[32m   1061\u001b[39m       composite_tensor_gradient.get_flat_tensors_for_gradients(\n\u001b[32m   1062\u001b[39m           output_gradients))\n\u001b[32m   1063\u001b[39m   output_gradients = [\u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m ops.convert_to_tensor(x)\n\u001b[32m   1064\u001b[39m                       \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m output_gradients]\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m flat_grad = \u001b[43mimperative_grad\u001b[49m\u001b[43m.\u001b[49m\u001b[43mimperative_grad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1067\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1068\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_targets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_sources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflat_sources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m=\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._persistent:\n\u001b[32m   1075\u001b[39m   \u001b[38;5;66;03m# Keep track of watched variables before setting tape to None\u001b[39;00m\n\u001b[32m   1076\u001b[39m   \u001b[38;5;28mself\u001b[39m._watched_variables = \u001b[38;5;28mself\u001b[39m._tape.watched_variables()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\imperative_grad.py:67\u001b[39m, in \u001b[36mimperative_grad\u001b[39m\u001b[34m(tape, target, sources, output_gradients, sources_raw, unconnected_gradients)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[32m     64\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m     65\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mUnknown value for unconnected_gradients: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % unconnected_gradients)\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_TapeGradient\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtape\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43msources_raw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mas_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43munconnected_gradients\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\eager\\backprop.py:148\u001b[39m, in \u001b[36m_gradient_function\u001b[39m\u001b[34m(op_name, attr_tuple, num_inputs, inputs, outputs, out_grads, skip_input_indices, forward_pass_name_scope)\u001b[39m\n\u001b[32m    146\u001b[39m     gradient_name_scope += forward_pass_name_scope + \u001b[33m\"\u001b[39m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    147\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.name_scope(gradient_name_scope):\n\u001b[32m--> \u001b[39m\u001b[32m148\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgrad_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmock_op\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mout_grads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m grad_fn(mock_op, *out_grads)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1716\u001b[39m, in \u001b[36m_MatMulGrad\u001b[39m\u001b[34m(op, grad)\u001b[39m\n\u001b[32m   1714\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_b:\n\u001b[32m   1715\u001b[39m   grad_a = gen_math_ops.mat_mul(grad, b, transpose_b=\u001b[38;5;28;01mTrue\u001b[39;00m, grad_a=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1716\u001b[39m   grad_b = \u001b[43mgen_math_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmat_mul\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_b\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1717\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t_a \u001b[38;5;129;01mand\u001b[39;00m t_b:\n\u001b[32m   1718\u001b[39m   grad_a = gen_math_ops.mat_mul(grad, b, grad_a=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\project\\chatbot_dl\\.venv\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py:6230\u001b[39m, in \u001b[36mmat_mul\u001b[39m\u001b[34m(a, b, transpose_a, transpose_b, grad_a, grad_b, name)\u001b[39m\n\u001b[32m   6228\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   6229\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m6230\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   6231\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMatMul\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranspose_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtranspose_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   6232\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtranspose_b\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_a\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgrad_b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_b\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6233\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   6234\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# í•™ìŠµ ì‹œí‚¤ê¸°\n",
    "# ì˜µí‹°ë§ˆì´ì €\n",
    "import keras\n",
    "adam = keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-8)\n",
    "\n",
    "steps = len(chat_data) // batch_size # í•œ ì—í¬í¬ë‹¹ ë°°ì¹˜ ë°˜ë³µ\n",
    "epochs = 1\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0\n",
    "\n",
    "    for batch in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            result = model(batch, labels=batch)\n",
    "            batch_loss = tf.reduce_mean(result[0])\n",
    "            grads = tape.gradient(batch_loss, model.trainable_variables)\n",
    "            adam.apply_gradients(zip(grads, model.trainable_variables))\n",
    "        \n",
    "        train_loss += batch_loss\n",
    "    train_loss = train_loss / steps\n",
    "\n",
    "    print(f\"epoch: {epoch+1}, loss={train_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc8c456",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"chatbot.weights.h5\") # ëª¨ë¸ ê°€ì¤‘ì¹˜ ì €ìž¥"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
